{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def features_probability(pan_series, lenth):\n",
    "    \"\"\"\n",
    "    Compute a specific feature probability given that panda series\n",
    "    :param pan_series:  'A panda series contains all data for that feature'\n",
    "    :param lenthï¼š lenth of the pandas series\n",
    "    Output: feature_prob  'A dictionay with key as data value and a probaility corresponding to probability of occurance'\n",
    "            that repesent 'P(xi|y)' in Naive Bayes\n",
    "    Example:\n",
    "    '>>> features_probability(df['loan_type'])\n",
    "    '>>> '{1: 0.7726327301673637,\n",
    "         2: 0.148994405648276,\n",
    "         3: 0.07526288084019156,\n",
    "         4: 0.0031099833441687666}'\n",
    "    \"\"\"\n",
    "    assert isinstance(pan_series, pd.core.series.Series)\n",
    "    return dict(pan_series.value_counts() / lenth)\n",
    "\n",
    "\n",
    "def train_feature_probability(df):\n",
    "    \"\"\"\n",
    "    Compute all features'probability as a list of dictionaries\n",
    "    :param 'df' training_data dataframe\n",
    "    Output: List of dictionaries that represens joint distribution of all features 'P(x|y)'\n",
    "    \"\"\"\n",
    "    assert isinstance(df, pd.core.frame.DataFrame)\n",
    "    train_features_list = [df['loan_type'], df['property_type'], df['loan_purpose'],\n",
    "                           df['owner_occupancy'],\n",
    "                           df['preapproval'],\n",
    "                           df['applicant_ethnicity'], df['applicant_race_1'], df['applicant_sex'],\n",
    "                           df['loan_amount_000s']]  # ,df['action_taken']]\n",
    "    df = pd.concat(train_features_list, axis=1)\n",
    "    df = df.dropna()\n",
    "    return [features_probability(df.iloc[:, i], len(df)) for i in range(len(df.columns) - 1)], df\n",
    "\n",
    "\n",
    "def loan_prediction(x, approved_dict, not_approved_dict, df_a, df_na, P_a, P_na):\n",
    "    \"\"\"\n",
    "    Given a loan applicant information as a pd.series. Compute how likely he/she will get the loan\n",
    "    Input: 'df_a' A dataframe that contians all Approved datasets\n",
    "            'df_na' A dataframe that contians all Unapproved datasets\n",
    "    Output: A string that that represents the predicted loan application result\n",
    "    \"\"\"\n",
    "    assert isinstance(x, pd.core.series.Series)\n",
    "    assert isinstance(approved_dict,list)\n",
    "    assert isinstance(not_approved_dict, list)\n",
    "    assert isinstance(df_na,pd.core.frame.DataFrame)\n",
    "    assert isinstance(df_a,pd.core.frame.DataFrame)\n",
    "    assert isinstance(P_a, int) or isinstance(P_a, float)\n",
    "    assert isinstance(P_na, int) or isinstance(P_a, float)\n",
    "    assert P_a + P_na == 1 and P_a >=0 and P_na >= 0\n",
    "\n",
    "    # print(P_a,P_na)\n",
    "    def get_prob_of_loan_from_approved(x):\n",
    "        \"\"\"\n",
    "        Get the probability of loan amount x from approved datasets\n",
    "        \"\"\"\n",
    "        d = np.array(df_a['loan_amount_000s'].astype(int))\n",
    "        return ((d > math.floor(x) - 5).sum() - (d > math.ceil(x) + 5).sum()) / len(d)\n",
    "\n",
    "    def get_prob_of_loan_from_unapproved(x):\n",
    "        \"\"\"\n",
    "        Get the probability of loan amount x from un_approved datasets\n",
    "        \"\"\"\n",
    "        d = np.array(df_na['loan_amount_000s'].astype(int))\n",
    "        return ((d > math.floor(x) - 5).sum() - (d > math.ceil(x) + 5).sum()) / len(d)\n",
    "\n",
    "    test_features_list = ['loan_type', 'property_type', 'loan_purpose', 'owner_occupancy', 'preapproval',\n",
    "                          'applicant_ethnicity', 'applicant_race_1', 'applicant_sex', 'loan_amount_000s']\n",
    "\n",
    "    array_of_x = [x[i] for i in test_features_list]\n",
    "    p_x_a = 1\n",
    "    p_x_na = 1\n",
    "    for count, item in enumerate(array_of_x):\n",
    "        if count != len(array_of_x) - 2:\n",
    "            p_x_a *= approved_dict[count][item]\n",
    "            p_x_na *= not_approved_dict[count][item]\n",
    "        else:\n",
    "            p_x_a *= get_prob_of_loan_from_approved(item)\n",
    "            p_x_na *= get_prob_of_loan_from_unapproved(item)\n",
    "            break\n",
    "    p_x_a *= P_a\n",
    "    p_x_na *= P_na\n",
    "    # return  \"Higher Probability You wil Get the Loan\" if p_x_a> p_x_na else \"Higher Probability You wil not Get the Loan\"\n",
    "    return 1 if p_x_a > p_x_na else 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\liuzh\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3071: DtypeWarning: Columns (34,36,38,42,44,46,48) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hmda_2017_ca_all-records_labels.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# groupby action taken\n",
    "a = df.groupby('action_taken')\n",
    "t1 = a.get_group(1)\n",
    "t2 = a.get_group(2)\n",
    "t8 = a.get_group(8)\n",
    "t3 = a.get_group(3)\n",
    "t7 = a.get_group(7)\n",
    "\n",
    "# generate approve dataframe and not-approved dataframe\n",
    "df_a = pd.concat([t1, t2, t8], ignore_index=True)\n",
    "df_na = pd.concat([t3, t7], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approved: [{1: 0.7987603860634738, 2: 0.1296041076981744, 3: 0.0689145858733424, 4: 0.0027209203650093725}, {1: 0.9781069569841073, 2: 0.011388550221014357, 3: 0.010504492794878268}, {3: 0.49189793057517445, 1: 0.43952477885136987, 2: 0.06857729057345571}, {1: 0.871660212581974, 2: 0.11817688667844693, 3: 0.010162900739579026}, {3: 0.8326574895132314, 2: 0.14282737248035576, 1: 0.024515138006412907}, {2: 0.6550178046802408, 1: 0.19871634432049498, 3: 0.13046560715839453, 4: 0.015800243840869664}, {5: 0.6307808815867918, 6: 0.15342102295004484, 2: 0.14330646070885722, 3: 0.03896620064773588, 7: 0.01546294854098299, 4: 0.009699925343874706, 1: 0.008362560221712579}, {1: 0.6425636591169094, 2: 0.26857621638460255, 3: 0.07335528259223253, 4: 0.01550484190625554}]\n",
      "Not Approved: [{1: 0.7919277348506653, 2: 0.1315429406425045, 3: 0.07441273496136559, 4: 0.002116589545464609}, {1: 0.9550601102574888, 2: 0.04105209555649036, 3: 0.0038877941860207673}, {3: 0.6474284322624926, 1: 0.23238204884096797, 2: 0.1201895188965395}, {1: 0.8756481501981536, 2: 0.12026922310536453, 3: 0.004082626696481945}, {3: 0.9290012619833063, 2: 0.06305045719219785, 1: 0.00794828082449576}, {2: 0.5972723448535435, 1: 0.22924701662718355, 3: 0.16959727234485356, 4: 0.003883366174419377}, {5: 0.5733256581132242, 6: 0.2145725861801758, 2: 0.12136294197090797, 3: 0.05931764341222574, 1: 0.015157083711559324, 4: 0.012703965284389045, 7: 0.003560121327517878}, {1: 0.602200721765891, 2: 0.28513295104833175, 3: 0.10910620585825935, 4: 0.003560121327517878}]\n"
     ]
    }
   ],
   "source": [
    "#get the posterior proability P(x|y) for each class\n",
    "approved_dict, df_a1 = train_feature_probability(df_a)\n",
    "not_approved_dict, df_na1 = train_feature_probability(df_na)\n",
    "\n",
    "P_a = len(df_a1) / (len(df_a1) + len(df_na1))\n",
    "P_na = len(df_na1) / (len(df_a1) + len(df_na1))\n",
    "\n",
    "# training error using only d_na and d_a\n",
    "df3 = df_a.append(df_na, ignore_index=True)\n",
    "df_4 = df3.sample(frac=1).reset_index(drop=True)\n",
    "print('Approved:', approved_dict)\n",
    "print('Not Approved:', not_approved_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29\n"
     ]
    }
   ],
   "source": [
    "# training error using only d_na and d_a\n",
    "\n",
    "#combine two dataset and shuffle it\n",
    "df3 = df_a.append(df_na, ignore_index=True)\n",
    "df_4 = df3.sample(frac=1).reset_index(drop=True)\n",
    "#using 2000000 training data to get the error rate\n",
    "truth = df_4['action_taken'][:200000]\n",
    "truth = np.array(truth)\n",
    "truth = truth[:, None]\n",
    "\n",
    "def foo(x):\n",
    "    if x == 1 or x == 2 or x == 8:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "truth = np.apply_along_axis(foo, 1, truth)\n",
    "\n",
    "result = []\n",
    "lenth = 200000\n",
    "for i in range(lenth):\n",
    "    result.append(loan_prediction(df_4.iloc[i],approved_dict,not_approved_dict,df_a1,df_na1,P_a,P_na))\n",
    "result = np.array(result)\n",
    "error = np.logical_xor(result, truth).sum()/lenth\n",
    "print(error)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
